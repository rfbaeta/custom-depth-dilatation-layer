{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c08ac9f-8747-4ac8-954b-5540710f25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://discuss.pytorch.org/t/convolution-that-only-take-channel-wise-summation/21240\n",
    "#https://auro-227.medium.com/writing-a-custom-layer-in-pytorch-14ab6ac94b77\n",
    "#https://towardsdatascience.com/how-to-build-your-own-pytorch-neural-network-layer-from-scratch-842144d623f6\n",
    "#https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_deep-learning-computation/custom-layer.ipynb\n",
    "#https://discuss.pytorch.org/t/custom-convolution-dot-product/14992/12\n",
    "#https://discuss.pytorch.org/t/efficiently-slicing-tensor-like-a-convolution/44840/2\n",
    "#https://discuss.pytorch.org/t/custom-a-new-convolution-layer-in-cnn/43682/14\n",
    "#https://towardsdatascience.com/convolutional-layer-hacking-with-python-and-numpy-e5f64812ca0c\n",
    "#https://github.com/pskugit/custom-conv2d\n",
    "#https://discuss.pytorch.org/t/custom-nn-conv2d/62068\n",
    "#https://stackoverflow.com/questions/59149785/custom-conv2d-operation-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32f08f63-8924-4f4c-9414-51879497dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a745426e-d3e5-46f5-ac95-9e2fcb16f1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward computation thru model: tensor([[ 1.2722, -0.6224]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "class MyLinearLayer(nn.Module):\n",
    "    \"\"\" Custom Linear layer but mimics a standard linear layer \"\"\"\n",
    "    def __init__(self, size_in, size_out):\n",
    "        super().__init__()\n",
    "        self.size_in, self.size_out = size_in, size_out\n",
    "        weights = torch.Tensor(size_out, size_in)\n",
    "        self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "        bias = torch.Tensor(size_out)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "\n",
    "        # initialize weights and biases\n",
    "        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weights)\n",
    "        bound = 1 / math.sqrt(fan_in)\n",
    "        \n",
    "        #Checar uniform aqui\n",
    "        nn.init.uniform_(self.bias, -bound, bound)  # bias init\n",
    "\n",
    "    def forward(self, x):\n",
    "        w_times_x= torch.mm(x, self.weights.t())\n",
    "        return torch.add(w_times_x, self.bias)  # w times x + b\n",
    "\n",
    "\n",
    "class BasicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 128, 3)\n",
    "        self.linear = nn.Linear(256, 2)\n",
    "        #self.linear = MyLinearLayer(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self. conv(x)\n",
    "        x = x.view(-1, 256)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "torch.manual_seed(0)  #  for repeatable results\n",
    "basic_model = BasicModel()\n",
    "basic_model2 = BasicModel()\n",
    "inp = np.array([[[[1,2,3,4],  # batch(=1) x channels(=1) x height x width\n",
    "                  [1,2,3,4],\n",
    "                  [1,2,3,4]]]])\n",
    "x = torch.tensor(inp, dtype=torch.float)\n",
    "print('Forward computation thru model:', basic_model(copy.deepcopy(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682bdfa-185a-4425-b505-ba6d82df475a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b5980-69d6-498f-be1c-f967ba1b319e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
